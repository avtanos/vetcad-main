# Запуск Ollama для AI Ассистента

## Быстрый запуск

### Windows

1. **Автоматический запуск:**
   - Ollama обычно запускается автоматически после установки
   - Проверьте в системном трее (правый нижний угол) иконку Ollama

2. **Ручной запуск:**
   - Найдите "Ollama" в меню Пуск и запустите
   - Или откройте командную строку и выполните:
     ```bash
     ollama serve
     ```

### Linux/Mac

```bash
ollama serve
```

## Проверка работы

### 1. Проверьте, что сервер запущен

```bash
curl http://localhost:11434/api/tags
```

Должен вернуть список установленных моделей.

### 2. Проверьте установленные модели

```bash
ollama list
```

Должна быть видна `llama3.2:1b`

### 3. Тестовый запрос

```bash
ollama run llama3.2:1b "Привет"
```

## Автозапуск (Windows)

Для автоматического запуска Ollama при старте системы:

1. Нажмите `Win + R`
2. Введите `shell:startup`
3. Создайте ярлык на Ollama в этой папке

## Проблемы

### Ollama не запускается

- Проверьте, что Ollama установлен
- Перезагрузите компьютер
- Переустановите Ollama

### Порт 11434 занят

- Закройте другие приложения, использующие этот порт
- Или измените порт в настройках Ollama

### Модель не найдена

```bash
ollama pull llama3.2:1b
```

## После запуска Ollama

1. Перезапустите бэкенд сервер (если он уже запущен)
2. AI ассистент будет работать с полной функциональностью
3. Откройте фронтенд и протестируйте чат

